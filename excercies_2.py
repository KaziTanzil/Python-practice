# -*- coding: utf-8 -*-
"""Python Excercies 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1epGVvHF729iF7Cy83zcX348l1bhDwSo8

**Exercise**

###### Let's consider vectors consisting of only ones and zeros. Let us also assume an additional convention for representing such a vector. For example, a vector:

###### u = [0, 1, 1, 0, 1, 0, 1, 0]
###### we will present as a sequence:
###### '01101010'

###### For the vectors so defined, we can determine the Hamming distance. The Hamming distance of vectors u and v is the number of elements where the vectors u and v are different.

###### Example: The Hamming distance of the vectors '1100100', '1010000' is equal to 3.

###### Implement a function called hamming_distance() that returns the Hamming distance of two vectors. To calculate the Hamming distance, the vectors must be of the same length. If the vectors are of different lengths raise the ValueError with the following message:

###### 'Both vectors must be the same length.'

###### Example:

###### [IN]: hamming_distance('01101010', '11011011')
###### [OUT]: 4

###### Example:

###### [IN]: hamming_distance('110', '10100')
###### [OUT]: ValueError: Both vectors must be the same length.

###### You just need to implement the hamming_distance() function. The tests run several test cases to validate the solution.
"""

def hamming_distance(vector1,vecter2):
    if len(vector1) == len(vecter2): #check if the two vectors are the same length
        return sum([1 for i in range(len(vector1)) if vector1[i] != vecter2[i]]) #return the sum of the number of differences between the two vectors

    else:
        raise ValueError('Both vectors must be the same length.') #raise an error if the vectors are not the same length

print(hamming_distance('01101010', '11011011'))

"""** **bold text**Exercise**

###### Let's consider vectors consisting of only ones and zeros. Let us also assume an additional convention for representing such a vector. For example, a vector:

###### u = [0, 1, 1, 0, 1, 0, 1, 0]

###### we will present as a sequence:

###### '01101010'

###### For the vectors so defined, we can determine the Hamming distance. The Hamming distance of vectors u and v is the number of elements where the vectors u and v are different.

###### Example: The Hamming distance of the vectors '1100100', '1010000' is equal to 3.

###### A function called hamming_distance() is implemented that returns the Hamming distance of two vectors:

###### def hamming_distance(u, v):
######     if len(u) != len(v):
######        raise ValueError('Both vectors must be the same length.')
######    distance = 0
######    for i in range(len(u)):
######       if u[i] != v[i]:
######           distance += 1
######   return distance

###### The weight of the vector u is the Hamming distance of this vector from the zero vector. So in the case of vector '1001001' its weight is equal to the Hamming distance of vector '1001001' from vector '0000000'.

###### Implement a function called hamming_weight() that returns the weight of the vector. In the solution, you can use the hamming_distance() function. It is also worth paying attention to a slightly simpler implementation. The weight of a vector is equal to the number of ones in the vector.

###### Example:
###### [IN]: hamming_weight('110001010')
###### [OUT]: 4

###### Example:

###### [IN]: hamming_weight('110111')
###### [OUT]: 5

###### You only need to implement the hamming_weight() function. The tests run several test cases to validate the solution.
"""

def hamming_weight(vector):
    return sum(1 for bit in vector if bit == '1')

print(hamming_weight('110001010'))

"""**Exercise **

###### Consider the popular Scrabble game. Scrabble is a word game in which players score points by placing tiles, each bearing a single letter, onto a game board divided into a 15Ã—15 grid of squares. The tiles must form words that, in crossword fashion, read left to right in rows or downward in columns, and be included in a standard dictionary or lexicon.

###### The combined words are scored, and the game is won by the player who in total (in all moves) scores more points than each of the opponents. The number of points is calculated based on the letters in each word. Each letter has a specific, fixed point value.

###### Below are the scores for the English version:
###### blank tile - 0 pt (usually two in a set)
###### EAIONRTLSU - 1 pt
###### DG - 2 pt
###### BCMP - 3 pt
###### FHVWY - 4 pt
###### K - 5 pt
###### JX - 8 pt
###### QZ - 10 pt

###### Implement a function called score() that returns a result for one word. We assume that the given word is grammatically correct. We can represent a blank tile for simplicity as a space character ' '.

###### Tip: We can use the built-in collections module and the ChainMap class.

###### Example:

###### [IN]: score('python')
###### [OUT]: 14

###### Example:

###### [IN]: score('programming')
###### [OUT]: 19

###### You just need to implement the score() function. The tests run several test cases to validate the solution.
"""

# create letters lists
list1 = [l for l in 'EAIONRTLSU']
list2 = [l for l in 'DG']
list3 = [l for l in 'BCMP']
list4 = [l for l in 'FHVWY ']
list5 = ['K']
list6 = [l for l in 'JX']
list7 = [l for l in 'QZ']

def score(word):
    total = 0
    # iterate through each letter in the word
    for letter in word:
        letter = letter.upper()
        # check which list the letter is in and add the corresponding value to the total
        if letter in list1:
            total += 1
        elif letter in list2:
            total += 2
        elif letter in list3:
            total += 3
        elif letter in list4:
            total += 4
        elif letter in list5:
            total += 5
        elif letter in list6:
            total += 8
        elif letter in list7:
            total += 10
        else:
            pass
    return total

print(score('python'))

from collections import ChainMap

english_scoreboard = {
    ' ': 0,
    'EAIONRTLSU': 1,
    'DG': 2,
    'BCMP': 3,
    'FHVWY': 4,
    'K': 5,
    'JX': 8,
    'QZ': 10,
}

def score(word):
    scores = ChainMap(
        *[
            dict.fromkeys(letter, score) # create a dictionary with the letter as the key and the score as the value
            for letter, score in english_scoreboard.items() # iterate through the english_scoreboard dictionary
        ]
    )
    return sum([scores[letter.upper()] for letter in word]) # return the sum of the scores for each letter in the word

print(score('python'))

"""**Exercise **

###### Consider the problem below. We have given a sequence of characters, and we want to extract from it all the substrings of length n in the order they appear in the sequence.

###### For example, from a sequence of characters 'python' we can extract a 3-digit series:

###### ['pyt', 'yth', 'tho', 'hon']

###### or 4-digit:

###### ['pyth', 'ytho', 'thon']

###### Implement a function called get_slices() that takes two arguments:

###### sequence - the sequence of characters to be processed

###### length - length of the substrings to be extracted from the sequence

###### If the value of the length argument is less than 1, raise the ValueError with the message:

###### 'The length cannot be less than 1.'

###### If the value of the length argument is greater than the length of the given sequence, raise the ValueError with the message:

###### 'The length cannot be greater than sequence.'

###### Example:

###### [IN]: get_slices('esmartdata', 5)
###### [OUT]: ['esmar', 'smart', 'martd', 'artda', 'rtdat', 'tdata']

###### Example:

###### [IN]: get_slices('654646849173', 6)
###### [OUT]: ['654646', '546468', '464684', '646849', '468491', '684917', '849173']

###### You just need to implement the get_slices() function. The tests run several test cases to validate the solution.
"""

def get_slices(sequence, length):
    if length < 1:
        raise ValueError('The length cannot be less than 1.') #raise an error if the length is less than 1
    elif length > len(sequence):
        raise ValueError('The length cannot be greater than sequence.') #raise an error if the length is greater than the sequence
    else: #if the length is valid
        substrings = [] #create an empty list to store the substrings
        for i in range(len(sequence)-length+1): #iterate through the sequence
            substrings.append(sequence[i:i+length]) #append the substring to the substrings list

        return substrings

print(get_slices('esmartdata', 5))

"""**Exercise **

###### Below is an example of a 3x3 square matrix of numbers in spiral order:

###### [1, 2, 3]
###### [8, 9, 4]
###### [7, 6, 5]

###### An example of a 4x4 square matrix of numbers in spiral order:

###### [ 1,  2,  3, 4]
###### [12, 13, 14, 5]
###### [11, 16, 15, 6]
###### [10,  9,  8, 7]

###### We move clockwise, starting with the number 1 and increasing by 1.

###### Implement a function called spiral_matrix() that takes the size of the matrix as an argument and generates the matrix in spiral order with the given size. Present the solution in the form of nested lists.

###### Tip: You can use the itertools built-in module and the cycle class in your solution.

###### Example:

###### [IN]: spiral_matrix(1)
###### [OUT]: [[1]]

###### Example:

###### [IN]: spiral_matrix(2)
###### [OUT]: [[1, 2], [4, 3]]

###### Example:

###### [IN]: spiral_matrix(3)
###### [OUT]: [[1, 2, 3], [8, 9, 4], [7, 6, 5]]

###### You just need to implement the spiral_matrix() function. The tests run several test cases to validate the solution.
"""

from itertools import cycle

def spiral_matrix(size):
    """
    Generates a spiral matrix of the given size.

    Args:
        size (int): The size of the matrix.

    Returns:
        list: The generated spiral matrix.

    Raises:
        ValueError: If the size is less than 1.
    """
    if size < 1:
        raise ValueError('The size cannot be less than 1.')

    matrix = [[0] * size for _ in range(size)]  # Initialize the matrix with zeros
    directions = cycle([(0, 1), (1, 0), (0, -1), (-1, 0)])  # right, down, left, up
    current_direction = next(directions)
    row, col = 0, 0

    for num in range(1, size**2 + 1):
        matrix[row][col] = num  # Assign the current number to the matrix

        next_row = row + current_direction[0]  # Calculate the next row
        next_col = col + current_direction[1]  # Calculate the next column

        # Check if the next position is out of bounds or already filled
        if (
            next_row < 0 or next_row >= size or
            next_col < 0 or next_col >= size or
            matrix[next_row][next_col] != 0
        ):
            current_direction = next(directions)  # Change the direction
            row += current_direction[0]  # Update the row
            col += current_direction[1]  # Update the column
        else:
            row = next_row  # Move to the next row
            col = next_col  # Move to the next column

    return matrix

"""**Exercise **

###### A file called hashtags.txt containing hashtags related to sport is attached to the exercise:

######  #sport #fitness #training #motivation #gym #sports #workout #fit #football #love #instagood #fitnessmotivation #lifestyle #running #like #bodybuilding #healthy #instagram #health #soccer #follow #crossfit #photography #bhfyp #run#nature #fun #healthylifestyle #muscle #bhfyp #fashion #fitfam #gymlife #photooftheday #team #personaltrainer #nike #picoftheday #exercise #mma #sportlife #boxing #athlete #bike #basketball #happy #deporte #gymmotivation #strong #cycling #yoga #style #ufc #sportmotivation #fitnessgirl #calcio #instafit

###### Implement a function called clean_hashtags() that loads the included hashtags.txt file and does some cleanup. Extract hashtags up to 4 characters long. The '#' sign is not included in the length of the hashtag. For example, the hashtag '#gym' has a length of 3.

###### Also take care to remove duplicates, if any. Then return the alphabetically sorted hashtags as a list.

###### In response, call clean_hashtags() function and print the result to the console.

###### Expected result:

###### ['#bike', '#fit', '#fun', '#gym', '#like', '#love', '#mma', '#nike', '#run', '#team', '#ufc', '#yoga']
"""

# Create the hashtags.txt file with the specified content
file_content = """#sport #fitness #training #motivation #gym #sports #workout #fit #football #love #instagood #fitnessmotivation #lifestyle #running #like #bodybuilding #healthy #instagram #health #soccer #follow #crossfit #photography #bhfyp #run#nature #fun #healthylifestyle #muscle #bhfyp #fashion #fitfam #gymlife #photooftheday #team #personaltrainer #nike #picoftheday #exercise #mma #sportlife #boxing #athlete #bike #basketball #happy #deporte #gymmotivation #strong #cycling #yoga #style #ufc #sportmotivation #fitnessgirl #calcio #instafit"""

with open('hashtags.txt', 'w') as f:
    f.write(file_content)

# Now the hashtags.txt file exists and you can run the clean_hashtags function
def clean_hashtags():
    with open('hashtags.txt', 'r') as file: #open the file
        content = file.read() #read the file
    hashtags = content.split() #split the content into a list of hashtags
    # The problem description asks for hashtags up to 4 characters long (excluding '#')
    # So the length check should be len(hashtag[1:]) <= 4 or len(hashtag) <= 5 if including '#'
    # Based on the expected output ['#bike', '#fit', '#fun', '#gym', '#like', '#love', '#mma', '#nike', '#run', '#team', '#ufc', '#yoga']
    # it seems the length check should be for the characters after '#'.
    # The original code had len(hashtag) <= 5 which corresponds to length up to 4 excluding '#'.
    # Let's keep the condition that yields the expected output.
    short_hashtags = [
        hashtag for hashtag in hashtags if len(hashtag) <= 5 #filter out hashtags longer than 5 characters including '#'
    ]
    result = sorted(set(short_hashtags)) #sort the hashtags and remove duplicates
    return result


print(clean_hashtags())

"""**Exercise**

###### A file called hashtags.txt containing hashtags related to sport is attached to the exercise:

###### #sport #fitness #training #motivation #gym #sports #workout #fit #football #love #instagood #fitnessmotivation #lifestyle #running #like #bodybuilding #healthy #instagram #health #soccer #follow #crossfit #photography #bhfyp #run #nature #fun #healthylifestyle #muscle #bhfyp #fashion #fitfam #gymlife #photooftheday #team #personaltrainer #nike #picoftheday #exercise #mma #sportlife #boxing #athlete #bike #basketball #happy #deporte #gymmotivation #strong #cycling #yoga #style #ufc #sportmotivation #fitnessgirl #calcio #instafit

###### Implement a function called clean_hashtags() that takes three arguments:

###### input_file - filename containing hashtags

###### output_file - filename to which the hashtags should be saved

###### length - the maximum length of the hashtag

###### The '#' sign is not included in the length of the hashtag. For example, the hashtag '#gym' has a length of 3.

###### The clean_hashtags() function loads a file called input_file and does some hashtag cleanup. The function extracts hashtags up to length characters long and also removes duplicates. It then saves the alphabetically sorted hashtags to a file called output_file, saving each hashtag in a new line.

###### Example:

###### [IN]: clean_hashtags('hashtags.txt', 'clean.txt', 5)

###### The contents of the clean.txt file after calling the function:

###### #bhfyp #bike #fit #fun #gym #happy #like #love #mma #nike #run #sport #style #team #ufc #yoga

###### You just need to implement the clean_hashtags() function. The tests run several test cases to validate the solution.
"""

def clean_hashtags(input_file,output_file,length):
    with open (input_file,'r') as file: #open the file
        content = file.read() #read the file

    hashtags = content.split() #split the content into a list of hashtags
    short_hashtags = [x for x in hashtags if len(x) <= length+1] #iterate through the hashtags and filter out the hashtags that are longer than the specified length
    result = sorted(set(short_hashtags)) #sort the hashtags and remove duplicates

    with open(output_file,'w') as file: #open the output file
        for hashtag in result: #iterate through the hashtags
            file.write(hashtag + '\n') #write the hashtag to the output file

clean_hashtags('hashtags.txt','short_hashtags.txt',5)

"""**Exercise**

###### The exercise includes a file called binary.txt containing numbers in binary system (each number is on a separate line.):

###### 0111111000100101
###### 1010111100000010
###### 0010110000011010
###### 1111000101111100
###### 0100101101000110
###### 0001001000011110
###### 0000011011010101
###### 0010100001101000
###### 0100001100001101
###### 0001111111000001
###### 0111101000000100
###### 1010100010001011
###### 0010001000011000
###### 0100010011110110
###### 0010010011111011

###### Implement a function called binary_to_int() that reads the included binary.txt file and converts the given numbers to decimal system. Return the numbers as a list.

###### Example:

###### [IN]: binary_to_int()
###### [OUT]: [32293, 44802, 11290, 61820, 19270, 4638, 1749, 10344, 17165, 8129, 31236, 43147, 8728, 17654, 9467]

###### You just need to implement the binary_to_int() function. The tests run several test cases to validate the solution.
"""

def binary_to_int():
    with open('binary.txt','r') as file: #open the file
        content = file.read()  #read the file
    str_list = content.split() #split the content into a list of binary strings
    int_list = [(int(x, 2)) for x in str_list] #convert the binary strings to integers
    return int_list #return the list of integers

print(binary_to_int())

"""**Exercise**

###### The exercise includes a file users.json containing data about users of a certain application.

###### Implement a function called filter_active_users(), which loads the attached users.json file and extracts all active users (is_active -> true):

###### "is_active": true

###### Then dump active users to a new active_users.json file (set indent level to 2).

###### In the solution, use the built-in json package.

###### Example:



###### [IN]: filter_active_users()


###### The content of the active_users.json file after calling the function:

###### [{"id": 2,"first_name": "Lukas","last_name": "Cottrill","email": "lcottrill1@linkedin.com","gender": null, "is_active": true,},{"id": 3,"first_name": "Heath", "last_name": "Rourke","email": "hrourke2@t.co","gender": "Genderfluid","is_active": true,},{"id": 4,"first_name": "Lucie","last_name": "Brunetti","email": "lbrunetti3@bbb.org","gender": "Non-binary","is_active": true,},{"id": 5,"first_name": "Minette","last_name": "Graysmark","email": "mgraysmark4@fotki.com","gender": null,"is_active": true,}...]

###### You only need to implement the filter_active_users() function. The tests run several test cases to validate the solution.
"""

import json
from collections import ChainMap
from itertools import cycle

# Create the hashtags.txt file with the specified content
file_content = """#sport #fitness #training #motivation #gym #sports #workout #fit #football #love #instagood #fitnessmotivation #lifestyle #running #like #bodybuilding #healthy #instagram #health #soccer #follow #crossfit #photography #bhfyp #run#nature #fun #healthylifestyle #muscle #bhfyp #fashion #fitfam #gymlife #photooftheday #team #personaltrainer #nike #picoftheday #exercise #mma #sportlife #boxing #athlete #bike #basketball #happy #deporte #gymmotivation #strong #cycling #yoga #style #ufc #sportmotivation #fitnessgirl #calcio #instafit"""

with open('hashtags.txt', 'w') as f:
    f.write(file_content)

# Now the hashtags.txt file exists and you can run the clean_hashtags function
import json
from collections import ChainMap
from itertools import cycle

# Create the hashtags.txt file with the specified content
file_content = """#sport #fitness #training #motivation #gym #sports #workout #fit #football #love #instagood #fitnessmotivation #lifestyle #running #like #bodybuilding #healthy #instagram #health #soccer #follow #crossfit #photography #bhfyp #run#nature #fun #healthylifestyle #muscle #bhfyp #fashion #fitfam #gymlife #photooftheday #team #personaltrainer #nike #picoftheday #exercise #mma #sportlife #boxing #athlete #bike #basketball #happy #deporte #gymmotivation #strong #cycling #yoga #style #ufc #sportmotivation #fitnessgirl #calcio #instafit"""

with open('hashtags.txt', 'w') as f:
    f.write(file_content)

# Now the hashtags.txt file exists and you can run the clean_hashtags function
def clean_hashtags():
    with open('hashtags.txt', 'r') as file: #open the file
        pass # Add pass or some code here

"""**Exercise**

###### The exercise includes a file users.json containing data about users of a certain application.

###### Implement a function called json_to_csv() which loads the attached users.json file, converts the file contents to the csv (comma-separated values) format, and saves it to the users.csv file.

###### In the solution, use the built-in json package.

###### Example:

###### [IN]: json_to_csv()

###### The contents of the users.csv file after calling the function:

###### id,first_name,last_name,email,gender,is_active
###### 1,Huntington,McComiskie,hmccomiskie0@admin.ch,None,False
###### 2,Lukas,Cottrill,lcottrill1@linkedin.com,None,True
###### 3,Heath,Rourke,hrourke2@t.co,Genderfluid,True
###### 4,Lucie,Brunetti,lbrunetti3@bbb.org,Non-binary,True
###### 5,Minette,Graysmark,mgraysmark4@fotki.com,None,True
###### 6,Stormi,Thresher,sthresher5@umn.edu,Non-binary,True
###### 7,Rochella,Berry,rberry6@moonfruit.com,Female,False
###### 8,Lock,Pablo,lpablo7@networkadvertising.org,Genderqueer,False
###### 9,Anton,Hugnin,ahugnin8@flickr.com,Genderqueer,True
###### 10,Stephi,Jacqueme,sjacqueme9@exblog.jp,Male,False

###### You just need to implement the json_to_csv() function. The tests run several test cases to validate the solution.
"""

import json
import base64
from IPython.display import HTML

# Create the JSON content
users_json_content = """
[
    {"id": 1,"first_name": "Huntington","last_name": "McComiskie","email": "hmccomiskie0@admin.ch","gender": null, "is_active": false},
    {"id": 2,"first_name": "Lukas","last_name": "Cottrill","email": "lcottrill1@linkedin.com","gender": null,"is_active": true},
    {"id": 3,"first_name": "Heath","last_name": "Rourke","email": "hrourke2@t.co","gender": "Genderfluid","is_active": true},
    {"id": 4,"first_name": "Lucie","last_name": "Brunetti","email": "lbrunetti3@bbb.org","gender": "Non-binary","is_active": true},
    {"id": 5,"first_name": "Minette","last_name": "Graysmark","email": "mgraysmark4@fotki.com","gender": null,"is_active": true},
    {"id": 6,"first_name": "Stormi","last_name": "Thresher","email": "sthresher5@umn.edu","gender": "Non-binary","is_active": true},
    {"id": 7,"first_name": "Rochella","last_name": "Berry","email": "rberry6@moonfruit.com","gender": "Female","is_active": false},
    {"id": 8,"first_name": "Lock","last_name": "Pablo","email": "lpablo7@networkadvertising.org","gender": "Genderqueer","is_active": false},
    {"id": 9,"first_name": "Anton","last_name": "Hugnin","email": "ahugnin8@flickr.com","gender": "Genderqueer","is_active": true},
    {"id": 10,"first_name": "Stephi","last_name": "Jacqueme","email": "sjacqueme9@exblog.jp","gender": "Male","is_active": false}
]
"""

# Save JSON to file
with open('users.json', 'w') as f:
    f.write(users_json_content)

# Convert JSON to CSV
with open('users.json', 'r') as file:
    content = json.load(file)

if content:
    headers = list(content[0].keys())
    rows = [headers] + [[str(row.get(h, "")) for h in headers] for row in content]

csv_content = "\n".join([",".join(row) for row in rows])

# Encode to base64
b64 = base64.b64encode(csv_content.encode()).decode()

# Create auto-download HTML with JavaScript
html = f"""
<a id="download_link" download="users.csv" href="data:text/csv;base64,{b64}" style="display:none;">Download</a>
<script>
    document.getElementById('download_link').click();
</script>
"""

# Trigger the download
HTML(html)

"""**Exercise**"""

import json
import base64
from IPython.display import HTML, display
import pandas as pd

# Step 1: Write JSON to file
users_json_content = """
[
    {"id": 1,"first_name": "Huntington","last_name": "McComiskie","email": "hmccomiskie0@admin.ch","gender": null, "is_active": false},
    {"id": 2,"first_name": "Lukas","last_name": "Cottrill","email": "lcottrill1@linkedin.com","gender": null,"is_active": true},
    {"id": 3,"first_name": "Heath","last_name": "Rourke","email": "hrourke2@t.co","gender": "Genderfluid","is_active": true},
    {"id": 4,"first_name": "Lucie","last_name": "Brunetti","email": "lbrunetti3@bbb.org","gender": "Non-binary","is_active": true},
    {"id": 5,"first_name": "Minette","last_name": "Graysmark","email": "mgraysmark4@fotki.com","gender": null,"is_active": true},
    {"id": 6,"first_name": "Stormi","last_name": "Thresher","email": "sthresher5@umn.edu","gender": "Non-binary","is_active": true},
    {"id": 7,"first_name": "Rochella","last_name": "Berry","email": "rberry6@moonfruit.com","gender": "Female","is_active": false},
    {"id": 8,"first_name": "Lock","last_name": "Pablo","email": "lpablo7@networkadvertising.org","gender": "Genderqueer","is_active": false},
    {"id": 9,"first_name": "Anton","last_name": "Hugnin","email": "ahugnin8@flickr.com","gender": "Genderqueer","is_active": true},
    {"id": 10,"first_name": "Stephi","last_name": "Jacqueme","email": "sjacqueme9@exblog.jp","gender": "Male","is_active": false}
]
"""
with open('users.json', 'w') as f:
    f.write(users_json_content)

# Step 2: Load JSON as DataFrame
with open('users.json', 'r') as file:
    data = json.load(file)

df = pd.DataFrame(data)

# Step 3: Advanced Filter (e.g. is_active = True & gender not null)
filtered_df = df[(df["is_active"] == True) & (df["gender"].notnull())]

# Step 4: Export to CSV string
csv_content = filtered_df.to_csv(index=False)

# Step 5: Encode CSV and auto-download
b64 = base64.b64encode(csv_content.encode()).decode()
html = f"""
<a id="download_link" download="filtered_users.csv" href="data:text/csv;base64,{b64}" style="display:none;">Download</a>
<script>
    document.getElementById('download_link').click();
</script>
"""

# Step 6: Display filtered data and download trigger
print("Filtered Users Preview:")
display(filtered_df)
HTML(html)